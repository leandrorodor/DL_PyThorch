{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMap0tgRMa51xs3wK1qdDwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leandrorodor/DL_PyThorch/blob/main/c0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/sumantindurkhya/text-generation-from-shakespeare-s-play-pytorch"
      ],
      "metadata": {
        "id": "y9RUSrqK1AAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory"
      ],
      "metadata": {
        "id": "aXmAsc27zYu3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "EDiTBDrQzJSn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tM0OZVBFzJ8v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "s6cawZ2KzPHf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqWmRP2xzU4_",
        "outputId": "37eee1d5-634b-4f47-d23d-ed0fbddd834d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fd85b4179a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "seq_size = 32\n",
        "embedding_size = 64\n",
        "lstm_size = 64\n",
        "gradients_norm = 5\n",
        "# set device parameter\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "heEEN2o_zRFv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "ioa0ybllzzr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read document\n",
        "with open ('/content/alllines.txt', 'r') as f:\n",
        "    doc = f.read()"
      ],
      "metadata": {
        "id": "CCURQ2r2ztxT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation"
      ],
      "metadata": {
        "id": "ExqqQzWn1IFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of words from document\n",
        "def doc2words(doc):\n",
        "    lines = doc.split('\\n')\n",
        "    lines = [line.strip(r'\\\"') for line in lines]\n",
        "    words = ' '.join(lines).split()\n",
        "    return words"
      ],
      "metadata": {
        "id": "vySQTgh501Xv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removepunct(words):\n",
        "    punct = set(string.punctuation)\n",
        "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
        "    return words"
      ],
      "metadata": {
        "id": "VIMt-1dY1J7-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get vocab from word list\n",
        "def getvocab(words):\n",
        "    wordfreq = Counter(words)\n",
        "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
        "    return sorted_wordfreq"
      ],
      "metadata": {
        "id": "Gs2SyLa71MXu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get dictionary of int to words and word to int\n",
        "def vocab_map(vocab):\n",
        "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
        "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
        "    return int_to_vocab, vocab_to_int"
      ],
      "metadata": {
        "id": "rxSCrjhe1OpP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = removepunct(doc2words(doc))\n",
        "vocab = getvocab(words)\n",
        "int_to_vocab, vocab_to_int = vocab_map(vocab)"
      ],
      "metadata": {
        "id": "uObUpj3A1Que"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
        "    # generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
        "    word_ints = [vocab_to_int[word] for word in words]\n",
        "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
        "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
        "    Ys = np.zeros_like(Xs)\n",
        "    Ys[:-1] = Xs[1:]\n",
        "    Ys[-1] = Xs[0]\n",
        "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
        "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
        "    \n",
        "    # iterate over rows of Xs and Ys to generate batches\n",
        "    for i in range(0, num_batches*batch_size, batch_size):\n",
        "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
      ],
      "metadata": {
        "id": "q_oJYyg21S1e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "c2V7WaD71V3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModule(nn.Module):\n",
        "    # initialize RNN module\n",
        "    def __init__(self, n_vocab, seq_size=32, embedding_size=64, lstm_size=64):\n",
        "        super(RNNModule, self).__init__()\n",
        "        self.seq_size = seq_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size,\n",
        "                            lstm_size,\n",
        "                            batch_first=True)\n",
        "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
        "        \n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.dense(output)\n",
        "\n",
        "        return logits, state\n",
        "    \n",
        "    def zero_state(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))"
      ],
      "metadata": {
        "id": "lijZCyg71VDf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_and_train_op(net, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    return criterion, optimizer"
      ],
      "metadata": {
        "id": "S-_mr3tY1ZPP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
        "    net.eval()\n",
        "\n",
        "    state_h, state_c = net.zero_state(1)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for w in words:\n",
        "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "    \n",
        "    _, top_ix = torch.topk(output[0], k=top_k)\n",
        "    choices = top_ix.tolist()\n",
        "    choice = np.random.choice(choices[0])\n",
        "\n",
        "    words.append(int_to_vocab[choice])\n",
        "    \n",
        "    for _ in range(100):\n",
        "        ix = torch.tensor([[choice]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "        choice = np.random.choice(choices[0])\n",
        "        words.append(int_to_vocab[choice])\n",
        "\n",
        "    print(' '.join(words))"
      ],
      "metadata": {
        "id": "e7042fZZ1bOv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
        "    \n",
        "    # RNN instance\n",
        "    net = RNNModule(n_vocab, seq_size, embedding_size, lstm_size)\n",
        "    net = net.to(device)\n",
        "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
        "\n",
        "    iteration = 0\n",
        "    \n",
        "    for e in range(50):\n",
        "        batches = get_batches(words, vocab_to_int, batch_size, seq_size)\n",
        "        state_h, state_c = net.zero_state(batch_size)\n",
        "\n",
        "        # Transfer data to GPU\n",
        "        state_h = state_h.to(device)\n",
        "        state_c = state_c.to(device)\n",
        "        for x, y in batches:\n",
        "            iteration += 1\n",
        "\n",
        "            # Tell it we are in training mode\n",
        "            net.train()\n",
        "\n",
        "            # Reset all gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Transfer data to GPU\n",
        "            x = torch.tensor(x).to(device)\n",
        "            y = torch.tensor(y).to(device)\n",
        "\n",
        "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
        "            loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss_value = loss.item()\n",
        "\n",
        "            # Perform back-propagation\n",
        "            loss.backward(retain_graph=True)\n",
        "\n",
        "            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), gradients_norm)\n",
        "            \n",
        "            # Update the network's parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            if iteration % 100 == 0:\n",
        "                print('Epoch: {}/{}'.format(e, 200),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
        "\n",
        "            # if iteration % 1000 == 0:\n",
        "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
        "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
        "                \n",
        "    return net"
      ],
      "metadata": {
        "id": "9oL93fsn1dZf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "UxoW26l31jTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kQVse9z1gsf",
        "outputId": "25b9762c-a74f-4062-aa91-e38a14212a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/200 Iteration: 100 Loss: 6.7442827224731445\n",
            "Epoch: 0/200 Iteration: 200 Loss: 7.145484924316406\n",
            "Epoch: 0/200 Iteration: 300 Loss: 7.04975700378418\n",
            "Epoch: 0/200 Iteration: 400 Loss: 6.623109817504883\n",
            "Epoch: 0/200 Iteration: 500 Loss: 7.114477634429932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate text"
      ],
      "metadata": {
        "id": "bh4owf6C1sCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(device, rnn_net, ['hey', 'you'], len(vocab), vocab_to_int, int_to_vocab)"
      ],
      "metadata": {
        "id": "LxhCpaNy1ksf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT"
      ],
      "metadata": {
        "id": "Bclwxib63Oya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the RNN class\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "# Define the input and output sizes\n",
        "input_size = len(all_letters)\n",
        "output_size = len(all_letters)\n",
        "\n",
        "# Define the hidden size\n",
        "hidden_size = 128\n",
        "\n",
        "# Create the RNN\n",
        "rnn = RNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.005)\n",
        "\n",
        "# Function to turn a string into a tensor\n",
        "def input_tensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, input_size)\n",
        "    for i in range(len(line)):\n",
        "        tensor[i][0][all_letters.find(line[i])] = 1\n",
        "    return tensor\n",
        "\n",
        "# Function to turn a tensor into a string\n",
        "def output_tensor(line):\n",
        "    letter_indexes = [all_letters.find(line[i]) for i in range(len(line))]\n",
        "    return torch.LongTensor(letter_indexes)\n",
        "\n",
        "# Function to turn a one-hot tensor into a string\n",
        "def output_string(output):\n",
        "    s = \"\"\n",
        "    for i in range(len(output)):\n",
        "        s += all_letters[output[i]]\n",
        "    return s\n",
        "\n",
        "# Function to train the RNN\n",
        "def train(line_tensor, category_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return output, loss.item()\n",
        "\n",
        "# Function to evaluate the RNN\n",
        "def evaluate(line_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_t\n"
      ],
      "metadata": {
        "id": "ozQrgSzC3QLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}